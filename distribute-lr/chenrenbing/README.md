

思考题：

1. 什么情况下,模型参数数量会特别大,以致于单机存不下? 试着说明这种情况下,参数主要来自于模型的哪个部分?

   a.大量的稀疏特征(user id、item id、session id等）容易导致参数量过大，特征维度过亿。

   b.稠密特征在使用深层网络模型时，会导致参数量过大，如 ：千层的resnet

   c. 在a的基础上，使用深层网络模型。

    **特征维度高及使用深层模型的前提是：数据量足够大。否则容易过拟合且不收敛**

   那么是否存在稠密特征的维度过千万呢，从典型的实际场景来说，一般不存在。可以人为地构造高维度的稠密特征（对数值特征进行多项式组合），但实际上不会大规模的构造稠密特征，一是成本过高（大样本下，稠密特征的存储需要额外的较高的成本），高成本没有带来较高收益；二是可以使用深度模型，implicitly 学习复杂高阶地特征关系。故只需要考虑以上三种情况。

   a. 使用浅层模型，如LR等。此时，每个worker内有数千个样本，虽然特征维度很大，但是在样本数较少的情况下，单个worker内的包含的特征是有限的，因此每个worker只需要采用<key,value>的形式记录自身需要的参数值。

   b.

   c.使用embedding，在b的基础上，再进行操作。

   

2. 如果参数数量太大,要分布在多台机器上, Server 端和 Worker 端在执行pull和push的时候要做哪些修改?

   ​     每个worker需要的特征是有限的，或者说相对于整体而言，只是很小一部分。因此可以在Server端记录每个worker需要的参数，对于具体的Worker，Server pull时，只需要pull相对应的参数；同理，Worker push时，只需要向Server push自身有的参数梯度更新。可以使用<key,value>来记录参数。

     

3. 了解一下 AllReduce, 试着说明利用PS如何实现 AllReduce 操作?